{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name = 'X')\n",
    "Y = tf.placeholder(tf.float32, name = 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = W * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.26543 [ 0.91178334] [ 0.53119165]\n",
      "1 0.131042 [ 0.7816422] [ 0.46023998]\n",
      "2 0.0323402 [ 0.80134684] [ 0.45553511]\n",
      "3 0.0296993 [ 0.80454242] [ 0.44388935]\n",
      "4 0.0282754 [ 0.80941379] [ 0.4332945]\n",
      "5 0.0269321 [ 0.81397647] [ 0.4228701]\n",
      "6 0.0256528 [ 0.81845039] [ 0.41270548]\n",
      "7 0.0244343 [ 0.82281452] [ 0.40278423]\n",
      "8 0.0232737 [ 0.82707393] [ 0.39310157]\n",
      "9 0.0221681 [ 0.831231] [ 0.3836517]\n",
      "10 0.0211151 [ 0.83528805] [ 0.37442896]\n",
      "11 0.0201121 [ 0.83924758] [ 0.36542794]\n",
      "12 0.0191568 [ 0.84311199] [ 0.35664332]\n",
      "13 0.0182468 [ 0.84688354] [ 0.34806988]\n",
      "14 0.0173801 [ 0.85056424] [ 0.33970249]\n",
      "15 0.0165545 [ 0.85415661] [ 0.33153629]\n",
      "16 0.0157682 [ 0.85766256] [ 0.32356638]\n",
      "17 0.0150192 [ 0.86108428] [ 0.31578809]\n",
      "18 0.0143058 [ 0.86442369] [ 0.30819675]\n",
      "19 0.0136262 [ 0.86768287] [ 0.30078793]\n",
      "20 0.012979 [ 0.87086368] [ 0.2935572]\n",
      "21 0.0123625 [ 0.87396806] [ 0.2865003]\n",
      "22 0.0117752 [ 0.87699777] [ 0.27961302]\n",
      "23 0.0112159 [ 0.87995464] [ 0.27289131]\n",
      "24 0.0106831 [ 0.88284045] [ 0.2663312]\n",
      "25 0.0101757 [ 0.88565689] [ 0.25992879]\n",
      "26 0.00969233 [ 0.88840562] [ 0.25368029]\n",
      "27 0.00923194 [ 0.89108825] [ 0.24758197]\n",
      "28 0.00879341 [ 0.89370644] [ 0.24163029]\n",
      "29 0.00837572 [ 0.89626163] [ 0.23582163]\n",
      "30 0.00797787 [ 0.89875543] [ 0.23015265]\n",
      "31 0.00759892 [ 0.90118933] [ 0.22461997]\n",
      "32 0.00723796 [ 0.90356469] [ 0.21922025]\n",
      "33 0.00689415 [ 0.90588289] [ 0.21395034]\n",
      "34 0.00656667 [ 0.90814537] [ 0.20880711]\n",
      "35 0.00625474 [ 0.91035348] [ 0.20378754]\n",
      "36 0.00595764 [ 0.91250855] [ 0.19888863]\n",
      "37 0.00567465 [ 0.91461182] [ 0.19410749]\n",
      "38 0.0054051 [ 0.91666442] [ 0.18944125]\n",
      "39 0.00514836 [ 0.91866779] [ 0.18488723]\n",
      "40 0.0049038 [ 0.920623] [ 0.18044268]\n",
      "41 0.00467087 [ 0.92253119] [ 0.17610495]\n",
      "42 0.004449 [ 0.92439342] [ 0.17187148]\n",
      "43 0.00423767 [ 0.926211] [ 0.16773984]\n",
      "44 0.00403637 [ 0.92798477] [ 0.16370745]\n",
      "45 0.00384464 [ 0.92971599] [ 0.15977205]\n",
      "46 0.00366202 [ 0.93140554] [ 0.15593123]\n",
      "47 0.00348807 [ 0.93305457] [ 0.15218277]\n",
      "48 0.00332239 [ 0.93466383] [ 0.14852437]\n",
      "49 0.00316457 [ 0.93623453] [ 0.14495397]\n",
      "50 0.00301425 [ 0.93776739] [ 0.14146934]\n",
      "51 0.00287108 [ 0.93926346] [ 0.13806854]\n",
      "52 0.00273469 [ 0.94072348] [ 0.13474946]\n",
      "53 0.0026048 [ 0.94214845] [ 0.13151017]\n",
      "54 0.00248106 [ 0.94353914] [ 0.12834875]\n",
      "55 0.00236321 [ 0.9448964] [ 0.12526333]\n",
      "56 0.00225096 [ 0.94622111] [ 0.12225212]\n",
      "57 0.00214403 [ 0.94751388] [ 0.11931324]\n",
      "58 0.00204219 [ 0.94877565] [ 0.11644505]\n",
      "59 0.00194519 [ 0.95000702] [ 0.11364578]\n",
      "60 0.00185278 [ 0.95120883] [ 0.11091383]\n",
      "61 0.00176478 [ 0.95238173] [ 0.10824754]\n",
      "62 0.00168095 [ 0.95352644] [ 0.10564534]\n",
      "63 0.00160111 [ 0.95464361] [ 0.10310569]\n",
      "64 0.00152505 [ 0.95573395] [ 0.10062711]\n",
      "65 0.00145261 [ 0.95679808] [ 0.09820811]\n",
      "66 0.00138361 [ 0.95783663] [ 0.09584725]\n",
      "67 0.00131789 [ 0.95885026] [ 0.09354316]\n",
      "68 0.00125529 [ 0.95983946] [ 0.09129445]\n",
      "69 0.00119566 [ 0.96080482] [ 0.08909976]\n",
      "70 0.00113887 [ 0.96174717] [ 0.0869579]\n",
      "71 0.00108477 [ 0.96266663] [ 0.08486745]\n",
      "72 0.00103324 [ 0.9635641] [ 0.08282729]\n",
      "73 0.000984161 [ 0.96444005] [ 0.08083621]\n",
      "74 0.000937413 [ 0.96529484] [ 0.07889295]\n",
      "75 0.000892886 [ 0.96612912] [ 0.07699642]\n",
      "76 0.000850473 [ 0.96694338] [ 0.07514549]\n",
      "77 0.000810073 [ 0.96773803] [ 0.07333903]\n",
      "78 0.000771597 [ 0.96851361] [ 0.07157603]\n",
      "79 0.000734941 [ 0.96927047] [ 0.06985536]\n",
      "80 0.000700032 [ 0.97000921] [ 0.06817609]\n",
      "81 0.000666785 [ 0.97073025] [ 0.0665372]\n",
      "82 0.000635111 [ 0.97143382] [ 0.06493767]\n",
      "83 0.000604942 [ 0.97212052] [ 0.06337661]\n",
      "84 0.000576206 [ 0.97279072] [ 0.06185307]\n",
      "85 0.000548834 [ 0.97344476] [ 0.06036616]\n",
      "86 0.000522766 [ 0.97408319] [ 0.05891501]\n",
      "87 0.000497935 [ 0.97470623] [ 0.05749875]\n",
      "88 0.000474282 [ 0.97531426] [ 0.0561165]\n",
      "89 0.00045175 [ 0.97590762] [ 0.05476748]\n",
      "90 0.000430294 [ 0.97648686] [ 0.05345094]\n",
      "91 0.000409856 [ 0.97705209] [ 0.05216602]\n",
      "92 0.000390387 [ 0.97760379] [ 0.050912]\n",
      "93 0.000371845 [ 0.9781422] [ 0.0496881]\n",
      "94 0.000354179 [ 0.97866762] [ 0.04849361]\n",
      "95 0.000337357 [ 0.9791804] [ 0.04732785]\n",
      "96 0.000321331 [ 0.9796809] [ 0.04619012]\n",
      "97 0.00030607 [ 0.98016942] [ 0.04507976]\n",
      "98 0.000291527 [ 0.98064607] [ 0.04399604]\n",
      "99 0.000277681 [ 0.98111135] [ 0.04293841]\n",
      "X: 5, Y: [ 4.94849491]\n",
      "X: 2.5, Y: [ 2.49571681]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data,\n",
    "                                                           Y: y_data})\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "        \n",
    "    print('X: 5, Y:', sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print('X: 2.5, Y:', sess.run(hypothesis, feed_dict={X: 2.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
